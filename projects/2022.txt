1:"$Sreact.fragment"
2:I[19687,["177","static/chunks/app/layout-5c2840eb1b4c98d7.js"],"ScrollPositionProvider"]
3:I[69812,["177","static/chunks/app/layout-5c2840eb1b4c98d7.js"],"ScreenSizeProvider"]
4:I[23449,[],""]
5:I[47869,[],""]
7:I[38310,[],"OutletBoundary"]
9:I[38310,[],"MetadataBoundary"]
b:I[38310,[],"ViewportBoundary"]
d:I[95064,[],""]
:HL["/_next/static/media/904be59b21bd51cb-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93720efa6ffd49e4-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/a74fb1607b845cb0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/c856374feb52eee1-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/ceab0d995744415d-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/dbddaa124a0a717a-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/1fa8cf2f05a0adee.css","style"]
:HL["/_next/static/css/0fd64655698c4722.css","style"]
:HL["/_next/static/css/513b3eae8d1c2fb7.css","style"]
:HL["/_next/static/css/34014092a3379e7d.css","style"]
:HL["/_next/static/css/cffdef2a1383dafb.css","style"]
0:{"P":null,"b":"la2uECkxMnTt_NJLfAKkD","p":"","c":["","projects","2022"],"i":false,"f":[[["",{"children":["projects",{"children":[["project","2022","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/1fa8cf2f05a0adee.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/0fd64655698c4722.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"className":"__variable_4fe76a __variable_606277","lang":"en","children":["$","body",null,{"className":"__variable_069ab3","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]}]}]]}],{"children":["projects",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","projects","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["project","2022","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","projects","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/513b3eae8d1c2fb7.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/34014092a3379e7d.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/_next/static/css/cffdef2a1383dafb.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L7",null,{"children":"$L8"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","zJQEtdg2Yv5dwAPm7nfaY",{"children":[["$","$L9",null,{"children":"$La"}],["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
c:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Projects - Brainhack Western 2026"}],["$","meta","2",{"name":"description","content":"Projects pitched at Brainhack Western"}],["$","link","3",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"64x64"}]]
8:null
e:I[85471,["862","static/chunks/862-66cd4b330b6a89c4.js","45","static/chunks/45-f916d720bcb3974c.js","708","static/chunks/708-406bf8af93f7c666.js","555","static/chunks/app/projects/%5Bproject%5D/page-6fe18bb8b1b7a664.js"],"NavBar"]
10:I[2250,["862","static/chunks/862-66cd4b330b6a89c4.js","45","static/chunks/45-f916d720bcb3974c.js","708","static/chunks/708-406bf8af93f7c666.js","555","static/chunks/app/projects/%5Bproject%5D/page-6fe18bb8b1b7a664.js"],"default"]
12:I[19548,["862","static/chunks/862-66cd4b330b6a89c4.js","45","static/chunks/45-f916d720bcb3974c.js","708","static/chunks/708-406bf8af93f7c666.js","555","static/chunks/app/projects/%5Bproject%5D/page-6fe18bb8b1b7a664.js"],""]
13:I[26036,["862","static/chunks/862-66cd4b330b6a89c4.js","45","static/chunks/45-f916d720bcb3974c.js","708","static/chunks/708-406bf8af93f7c666.js","555","static/chunks/app/projects/%5Bproject%5D/page-6fe18bb8b1b7a664.js"],"default"]
11:T410,Being confused, freezing, or panicking while trying hard to stop,
re-direct, or stabilize a drone (or any such robot/toy) in sudden
counter-intuitive poses or environmental conditions is likely a
relatable experience for all of us. The idea here is about enhancing the
expression of our intent while controlling a robot remotely ‚Äî either in
real life or on a computer screen (simulation) ‚Äî while not replacing the
primary instrument of control (modality) but instead by also integrating
our brain states (thought) in the control loop as measured, for example,
through EEG. Specifically, for the scope of the hackathon, this could
mean developing a brain-machine interface for automatically assisting
the operator in emergency cases with ‚Äúsmart‚Äù control command reflexes or
‚Äútakeovers‚Äù. Such an approach can be beneficial in high-risk cases such
as remote handling of materials in nuclear facilities or it can also aid
the supervision of autonomous control, say in the context of
self-driving cars, to ultimately increase safety.6:["$","div",null,{"className":"_1n606ht0","children":[["$","$Le",null,{"displaySections":{"tutorial":false,"schedule":false,"twitterFeed":false},"splashMode":false,"registrationButton":"$Lf","projectUrl":"/projects/2026"}],["$","article",null,{"ref":"$undefined","style":"$undefined","children":[["$","h1",null,{"children":"Projects"}],null,["$","$L10",null,{"years":["2021","2022","2023","2025","2026"],"def":"2022"}],null,[["$","section","Safer-Multimodal-Teleoperation-of-Simulated-Robots",{"id":"Safer-Multimodal-Teleoperation-of-Simulated-Robots","children":[["$","h3",null,{"children":"Safer Multimodal Teleoperation of (Simulated) Robots"}],["$","div",null,{"className":"console ","children":["$","span",null,{"children":[[["$","p","p-0",{"children":"$11"}],"\n",["$","p","p-1",{"children":"For now, we could pick a particular type of simulated robot (industrial\narms, RC cars, drones, etc.) and focus on designing and implementing a\nparadigm for characterizing intended motion and surprise during\nundesired motion in both autonomous (with no user control but robot's\nself- and environmental influences) or semi-autonomous cases (including\nuser's control commands), i.e., we can aim to measure intent and\nsurprise given the user's control commands, the brain states, and robot\nstates during algorithmically curated cases of robot motion. This will\nhelp us detect such situations and also infer desired reactions to\naccordingly adjust control commands to achieve desired reactions during\nemergencies and, more generally, to augment real-time active control to\nmatch the desired motion. We can strive to keep the approach suitable\nfor generalizing well enough to robots of other types and/or\nmorphologies and to more unusual environments."}]],null,["$","div",null,{"children":[["$","span",null,{"className":"green","children":"Organizer: "}],["$","br",null,{}],[["$","div","Pranshu Malik",{"className":"d-flex","children":[["$","span",null,{"children":"¬†¬†-¬†"}],["$","div",null,{"children":["Pranshu Malik",[" ","(",["$","$L12",null,{"href":"https://github.com/pranshumalik14","children":["@","pranshumalik14"]}],")"]]}],["$","br",null,{}]]}]]]}]]}]}]]}],["$","section","Brain3DVis-AR/MR-MRI-Visualizer",{"id":"Brain3DVis-AR/MR-MRI-Visualizer","children":[["$","h3",null,{"children":"Brain3DVis: AR/MR MRI Visualizer"}],["$","div",null,{"className":"console ","children":["$","span",null,{"children":[[["$","p","p-0",{"children":["Application that uses a web-based front end where users can submit brain\nMRI volumes. The data is then processed on the application backend, a 3D\nmodel is generated, and is then accessible in a AR/VR environment. We\nare using the MERN stack for the web component and C#/Unity for the\nAR/VR application. We would love to work with people who have experience\nwith MRI volumetric segmentation or are interested in VR/AR data\nvisualization. ",["$","span","span-0",{"role":"img","aria-label":"slightly smiling face emoji","children":"üôÇ"}]]}]],null,["$","div",null,{"children":[["$","span",null,{"className":"green","children":"Organizer: "}],["$","br",null,{}],[["$","div","Liam Bilbie",{"className":"d-flex","children":[["$","span",null,{"children":"¬†¬†-¬†"}],["$","div",null,{"children":["Liam Bilbie",[" ","(",["$","$L12",null,{"href":"https://github.com/LiamBilbie","children":["@","LiamBilbie"]}],")"]]}],["$","br",null,{}]]}]]]}]]}]}]]}],["$","section","Functional-Atlas-Explorer",{"id":"Functional-Atlas-Explorer","children":[["$","h3",null,{"children":"Functional Atlas Explorer"}],["$","div",null,{"className":"console ","children":["$","span",null,{"children":[[["$","p","p-0",{"children":"\"What does the inferior frontal gyrus do?\" Googling this question\nreturns 93,400,000 results. A skim read of paper abstracts will give you\nsome ideas about its functions. But wouldn't it be useful to have an\ninteractive map where you can explore these functions in the brain?\nImagine clicking on a brain region and getting a word cloud of functions\nthat this region is highly involved in. That's what we will build!"}],"\n",["$","p","p-1",{"children":"We will create an interactive tool, useful for anyone wanting to explore\ntheir own functional data or openly available functional datasets.\nTogether with our functional fusion toolbox (in-house & soon to be\nreleased), it lets you integrate information from many different openly\navailable datasets (Human Connectome Project, etc)."}],"\n",["$","p","p-2",{"children":"During the project you will be able to use our existing toolbox to\nexplore these large datasets - as well as your own data! In addition,\nthis interactive map will provide a side by side view of your desired\nbrain regions and their connections with other brain regions. Click on a\nregion and you get a map of its functional connectivity to all other\nregions in the brain."}],"\n",["$","p","p-3",{"children":"The tool will help synthesize findings across studies (think Neurosynth,\nbut directly based on fMRI data) and aid interpretation of results as\nwell as planning of future experiments."}]],null,["$","div",null,{"children":[["$","span",null,{"className":"green","children":"Organizers: "}],["$","br",null,{}],[["$","div","Caroline Nettekoven",{"className":"d-flex","children":[["$","span",null,{"children":"¬†¬†-¬†"}],["$","div",null,{"children":["Caroline Nettekoven",[" ","(",["$","$L12",null,{"href":"https://github.com/carobellum","children":["@","carobellum"]}],")"]]}],["$","br",null,{}]]}],["$","div","Ladan Shahshahani",{"className":"d-flex","children":[["$","span",null,{"children":"¬†¬†-¬†"}],["$","div",null,{"children":["Ladan Shahshahani",[" ","(",["$","$L12",null,{"href":"https://github.com/lshahsha","children":["@","lshahsha"]}],")"]]}],["$","br",null,{}]]}]]]}]]}]}]]}],["$","section","DWI-Fiducials",{"id":"DWI-Fiducials","children":[["$","h3",null,{"children":"DWI Fiducials"}],["$","div",null,{"className":"console ","children":["$","span",null,{"children":[[["$","p","p-0",{"children":"Diffusion-Weighted Imaging (DWI) is a variant of the standard MRI\nsequence examining the diffusion rate of water molecules.  DWI or\nDiffusion MRI has allowed for the improved study of white matter\npathways across both diseased and healthy patients."}],"\n",["$","p","p-1",{"children":["The goal of the diffusion Fiducials or dFIDs project is to identify a\nset of anatomical landmarks on a variety of Diffusion-Weighted MRI\nimages that are both salient and have functional significance.  This\nwill be an extension of the previous Anatomical Fiducials (AFIDs)\nproject that has localized a set of 32 clinically-relevant landmarks in\nhumans, macaques, and PD patients in multiple imaging acquisitions (see\n",["$","a","a-0",{"href":"https://doi.org/10.1002/hbm.24693","children":"https://doi.org/10.1002/hbm.24693"}],")."]}],"\n",["$","p","p-2",{"children":"We are looking for students, researchers, and clinicians to determine\npotential fiducials across various acquisition types and models in DWI.\nThose with experience in acquiring diffusion images or who have an\ninterest in neuroimaging or anatomy are welcome to join!"}]],null,["$","div",null,{"children":[["$","span",null,{"className":"green","children":"Organizer: "}],["$","br",null,{}],[["$","div","Arun Thurairajah",{"className":"d-flex","children":[["$","span",null,{"children":"¬†¬†-¬†"}],["$","div",null,{"children":["Arun Thurairajah",null]}],["$","br",null,{}]]}]]]}]]}]}]]}]]],"className":"_1p0a9t10 container-lg"}],["$","footer",null,{"className":"_1d8l4x30","children":["$","div",null,{"ref":"$undefined","id":"$undefined","children":[["$","div",null,{"ref":"$undefined","children":[["$","div",null,{"className":"col-lg-6 d-flex flex-column justify-content-start align-items-start","children":[["$","h3",null,{"children":"Organizers"}],["$","p",null,{"className":"organizers","children":"Ali Tafakkor, Peter Van Dyken, Armin Panjehpour, Ali Ghavampour, Ricardo Alonso Rios Carrillo, Ronak Mohammady, Joud Abdulmajeed El-Shawa, Noran Almomen, Dryden Arseneau, Chelsea-Leigh Marie McKenzie, Abdulhai Aljaabary, Emily Cordeiro, Utkarsh Shukla, Cathryn Dunicliff, Khac Vinh Nguyen, Nya Yazdi, Nima Zargarnezhad, Ada Natalie Borawake, Deanne Wah, Chelsea Bo-Ra Kim, Sara Rostamidarounkola, Abdul Moiz Naqvi, Ali Khan"}]]}],null],"className":"row"}],["$","h3",null,{"id":"contact","children":"Contact"}],["$","$L13",null,{"email":"brainhack.western@gmail.com"}],["$","p",null,{"className":"_1d8l4x31","children":["Copyright ¬© ",2026," Brainhack Western"]}]],"className":"_1d1a9if0  container-lg"}]}]]}]
f:["$","div",null,{"className":"align-self-lg-center","children":["$","$L12",null,{"href":"/forms/registration","className":"button ","children":["$","div",null,{"className":"inner","children":["$","span",null,{"children":"Register Now"}]}]}]}]
